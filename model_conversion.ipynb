{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_conversion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGIn1LYrhnPy",
        "outputId": "dbc2f43d-f2db-417f-96e0-6ba78f56f1dc"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpFkG_8nUCwO",
        "outputId": "daec38f8-bf05-40f4-876d-72e5658144f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkVmRtUejDCn",
        "outputId": "1233fe6d-4b66-4d85-9cff-83a1dbfe7416"
      },
      "source": [
        "%cd /content/drive/MyDrive/21Spring/COMS\\ 6998/Project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/21Spring/COMS 6998/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FV83TMUVXEh",
        "outputId": "46d99e13-d1e2-44aa-b903-64b9ba3ef5e5"
      },
      "source": [
        "%cd /content/drive/MyDrive/21Spring/COMS\\ 6998/Project/6998-sec11-final-project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/21Spring/COMS 6998/Project/6998-sec11-final-project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ImWTSBjkgA2",
        "outputId": "e2ab542b-cfcc-4b4a-faa7-3fbc545ed694"
      },
      "source": [
        "%cd /content/drive/MyDrive/21Spring/COMS\\ 6998/Project/6998-sec11-final-project-sys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/21Spring/COMS 6998/Project/6998-sec11-final-project-sys\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox2f6lHGc242",
        "outputId": "b5ad3cc4-b874-48ae-9979-6facd80cba10"
      },
      "source": [
        "%cd /content/drive/MyDrive/21Spring/COMS\\ 6998/Project/Final_Project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/21Spring/COMS 6998/Project/Final_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqPeVY9Xa0MM"
      },
      "source": [
        "from vehicle_signature.contrastive import ContrastiveLoss\n",
        "from vehicle_signature.siamese import SiameseNetwork\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qwwlED0ha04"
      },
      "source": [
        "from vehicle_detection import detector\n",
        "class LoadModelTF:\n",
        "  @classmethod\n",
        "  def load_model(cls, model_path):\n",
        "    model = detector.get_detector()\n",
        "    model.predict(np.random.randn(1, 150, 150, 3))\n",
        "    model.load_weights(model_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnT1oHx1ha3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c13b37-6ef8-48e1-f478-4167c215db1a"
      },
      "source": [
        "model_keras = LoadModelTF.load_model(\"logs/vehicle_detection/simple_cnn/ckpt\")\n",
        "model_keras.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7dec8bfcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           (None, 150, 150, 16)      2368      \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 75, 75, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 75, 75, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 38, 38, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 38, 38, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 19, 19, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 92416)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 20)                1848340   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 2,242,889\n",
            "Trainable params: 2,242,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWjaC1PCwF4c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as utils\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "from functools import reduce\n",
        "from operator import __add__\n",
        "\n",
        "def compute_padding(k):\n",
        "    return (k - 1) // 2\n",
        "\n",
        "class TorchDetector(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchDetector, self).__init__()\n",
        "\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=7, stride=1, padding=compute_padding(7)),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=compute_padding(3)),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=compute_padding(3)),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=compute_padding(3)),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=compute_padding(3)),\n",
        "            nn.MaxPool2d(2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Defining the fully connected layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(92416, 20),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(20, 1), \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        output = self.cnn1(x)\n",
        "        print(output.shape)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        print(output.shape)\n",
        "        output = self.fc1(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrgAoJX27cPd"
      },
      "source": [
        "weights = model_keras.get_weights()\n",
        "torchdetector = TorchDetector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaStpW477tqm",
        "outputId": "032367fd-e091-47a4-b669-27aaf06529e5"
      },
      "source": [
        "torchdetector.cnn1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wWIdnRt8yzG",
        "outputId": "a8e68e21-acc1-4bfa-8d03-da78fac2ca09"
      },
      "source": [
        "torchdetector.fc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=92416, out_features=20, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Linear(in_features=20, out_features=1, bias=True)\n",
              "  (3): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgJFc0dG7GQl"
      },
      "source": [
        "torchdetector.cnn1[0].weight.data=torch.from_numpy(np.transpose(weights[0]))\n",
        "torchdetector.cnn1[0].bias.data=torch.from_numpy(weights[1])\n",
        "torchdetector.cnn1[1].weight.data=torch.from_numpy(np.transpose(weights[2]))\n",
        "torchdetector.cnn1[1].bias.data=torch.from_numpy(weights[3])\n",
        "torchdetector.cnn1[2].weight.data=torch.from_numpy(np.transpose(weights[4]))\n",
        "torchdetector.cnn1[2].bias.data=torch.from_numpy(weights[5])\n",
        "torchdetector.cnn1[3].weight.data=torch.from_numpy(np.transpose(weights[6]))\n",
        "torchdetector.cnn1[3].bias.data=torch.from_numpy(weights[7])\n",
        "torchdetector.cnn1[4].weight.data=torch.from_numpy(np.transpose(weights[8]))\n",
        "torchdetector.cnn1[4].bias.data=torch.from_numpy(weights[9])\n",
        "torchdetector.fc1[0].weight.data=torch.from_numpy(np.transpose(weights[10]))\n",
        "torchdetector.fc1[0].bias.data=torch.from_numpy(weights[11])\n",
        "torchdetector.fc1[2].weight.data=torch.from_numpy(np.transpose(weights[12]))\n",
        "torchdetector.fc1[2].bias.data=torch.from_numpy(weights[13])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlKUDNAC7GU6"
      },
      "source": [
        "torch.save(torchdetector.state_dict(), \"torch_detector.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7gUy9MH7GXZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsXePdZs7GaZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifyhN7O17GcR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrOipvwB7GeA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}